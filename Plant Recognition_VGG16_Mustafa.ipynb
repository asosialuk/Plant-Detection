{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ef34b79-64ac-4a49-84bb-10773aa18649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27540269-09b6-4526-a4d5-ef78d2bcabbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70295 files belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set=tf.keras.utils.image_dataset_from_directory(\n",
    "    'train',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de61632b-e946-4df3-b7f0-d4268337d50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17572 files belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_set=tf.keras.utils.image_dataset_from_directory(\n",
    "    'valid',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f5f4f90-db20-4129-a4db-e371c1c233c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 38), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75025bf6-6fcb-4019-8421-410b071b35a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten,Dropout,GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4baf3c8-3d9a-4175-922d-2883469ebc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "class TimingCallback(Callback):\n",
    "    def __init__(self, logs={}):\n",
    "        self.logs=[]\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.starttime = timer()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(timer()-self.starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b6658dd-6df1-4327-9692-42e54f30a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "                                patience=5,\n",
    "                                min_delta = 0.01,\n",
    "                                verbose=1,\n",
    "                                mode = 'min',\n",
    "                                monitor='val_loss')\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(\n",
    "                                    monitor=\"val_loss\",\n",
    "                                    patience=3,\n",
    "                                    episilon= 0.01,\n",
    "                                    factor=0.1,\n",
    "                                    cooldown = 4,\n",
    "                                    verbose=1)\n",
    "\n",
    "time_callback = TimingCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47880b7b-0120-491e-a9ba-5e5f2e28b283",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class=38\n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "for layer in base_model.layers: \n",
    "    layer.trainable = False\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3640fc28-f852-4260-b847-d461feff4403",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D()) \n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(n_class, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07eec61-452d-4478-9c4c-813791a7adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66b1317e-9231-4e70-aad6-a1a1708f731f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, None, None, 512)   14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              525312    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 38)                19494     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,784,294\n",
      "Trainable params: 1,069,606\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5c2d74d-183c-4b0b-8ba5-57c2d02d3d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2197/2197 [==============================] - 1003s 456ms/step - loss: 0.6433 - acc: 0.8111 - val_loss: 0.2984 - val_acc: 0.9010 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "2197/2197 [==============================] - 1121s 510ms/step - loss: 0.3517 - acc: 0.8893 - val_loss: 0.2692 - val_acc: 0.9160 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "2197/2197 [==============================] - 1025s 467ms/step - loss: 0.3040 - acc: 0.9066 - val_loss: 0.2573 - val_acc: 0.9214 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "2197/2197 [==============================] - 1004s 457ms/step - loss: 0.2739 - acc: 0.9162 - val_loss: 0.2478 - val_acc: 0.9226 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "2197/2197 [==============================] - 1051s 478ms/step - loss: 0.2552 - acc: 0.9226 - val_loss: 0.2534 - val_acc: 0.9270 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "2197/2197 [==============================] - 1000s 455ms/step - loss: 0.2444 - acc: 0.9291 - val_loss: 0.2586 - val_acc: 0.9280 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "2197/2197 [==============================] - ETA: 0s - loss: 0.2388 - acc: 0.9319\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "2197/2197 [==============================] - 950s 432ms/step - loss: 0.2388 - acc: 0.9319 - val_loss: 0.2664 - val_acc: 0.9285 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "2197/2197 [==============================] - 992s 452ms/step - loss: 0.1246 - acc: 0.9610 - val_loss: 0.1568 - val_acc: 0.9566 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "2197/2197 [==============================] - 981s 446ms/step - loss: 0.0858 - acc: 0.9714 - val_loss: 0.1502 - val_acc: 0.9575 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "2197/2197 [==============================] - 1025s 466ms/step - loss: 0.0725 - acc: 0.9762 - val_loss: 0.1483 - val_acc: 0.9600 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "2197/2197 [==============================] - 1042s 474ms/step - loss: 0.0632 - acc: 0.9788 - val_loss: 0.1474 - val_acc: 0.9607 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "2197/2197 [==============================] - 1006s 458ms/step - loss: 0.0565 - acc: 0.9801 - val_loss: 0.1463 - val_acc: 0.9616 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "2197/2197 [==============================] - 968s 440ms/step - loss: 0.0512 - acc: 0.9820 - val_loss: 0.1457 - val_acc: 0.9623 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "2197/2197 [==============================] - 1036s 472ms/step - loss: 0.0461 - acc: 0.9838 - val_loss: 0.1495 - val_acc: 0.9614 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "2197/2197 [==============================] - 1060s 482ms/step - loss: 0.0440 - acc: 0.9851 - val_loss: 0.1501 - val_acc: 0.9620 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "2197/2197 [==============================] - ETA: 0s - loss: 0.0423 - acc: 0.9853\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "2197/2197 [==============================] - 1000s 455ms/step - loss: 0.0423 - acc: 0.9853 - val_loss: 0.1489 - val_acc: 0.9633 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "2197/2197 [==============================] - 950s 432ms/step - loss: 0.0346 - acc: 0.9880 - val_loss: 0.1461 - val_acc: 0.9636 - lr: 1.0000e-05\n",
      "Epoch 17: early stopping\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 20 \n",
    "model_history = model.fit(\n",
    "            training_set,\n",
    "            validation_data =validation_set,\n",
    "            epochs = epochs,\n",
    "            callbacks = [\n",
    "                         reduce_learning_rate,\n",
    "                         early_stopping,\n",
    "                         time_callback\n",
    "                        ],\n",
    "            verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
